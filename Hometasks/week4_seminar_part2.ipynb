{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of week4_seminar_part2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "AsS9kKt-Ic5U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## DSSM and beyond\n",
        "\n",
        "Повторяем идею из [Learning Deep Structured Semantic Models for Web Search using Clickthrough Data](https://www.microsoft.com/en-us/research/publication/learning-deep-structured-semantic-models-for-web-search-using-clickthrough-data/)\n",
        "\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/v-liaha/v-liaha.github.io/master/assets/dssm.png\" width=600>\n",
        "\n",
        "В качестве энкодера используем **conv - maxpooling**\n",
        "\n",
        "Скачиваем данные [Quora Question Pairs](https://www.kaggle.com/quora/question-pairs-dataset)\n",
        "\n",
        "**Описание данных:**\n",
        "\n",
        "* id - the id of a training set question pair\n",
        "* qid1, qid2 - unique ids of each question (only available in train.csv)\n",
        "* question1, question2 - the full text of each question\n",
        "* is_duplicate - the target variable, set to 1 if question1 and question2 have essentially the same meaning, and 0 otherwise."
      ]
    },
    {
      "metadata": {
        "id": "nfD9Oxo9Ic5Y",
        "colab_type": "code",
        "outputId": "e0b3e083-40aa-41e4-f6f4-0dd9c8846b71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "# tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "T8MmXs93Ic53",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# choose the GPU to use\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R_M3u4dGIc6L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "time_steps = 12\n",
        "vocab_size = 7000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ak8LmFBLIc6U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Задание 1**\n",
        "\n",
        "Написать функцию, которая приводит строку к нижнему регистру, оставляет запятые, числа, вопросительный и восклицательный знаки"
      ]
    },
    {
      "metadata": {
        "id": "JPyK0cojIc6e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tokenize_string(string):\n",
        "    \n",
        "    re.sub(r'[^A-Za-z,?!]', '', string).lower()\n",
        "    \n",
        "    return string\n",
        "\n",
        "\n",
        "def vectorize(data, tokenizer, time_steps=time_steps):\n",
        "    data = tokenizer.texts_to_sequences(data)\n",
        "    data = pad_sequences(data, maxlen=time_steps, padding='post')\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PbegQaa_Ic6m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Обработка данных\n",
        "\n",
        "Поменяем постановку задачи: теперь вместо того, чтобы предсказывать, с какой вероятностью данные примеры являются дубликатами, будем находить дубликаты среди пула примеров."
      ]
    },
    {
      "metadata": {
        "id": "BpqQbQRTIc6o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# nrows -- сколько строк с *.csv файла загрузить в память\n",
        "data = pd.read_csv('questions.csv', nrows=1000)\n",
        "\n",
        "# оставляем только дубликаты\n",
        "data = data[data['is_duplicate'] == 1]\n",
        "data = data.dropna()\n",
        "data = data.rename({'question1': 'query', 'question2': 'd+'}, axis=1)\n",
        "\n",
        "# очищаем данные от шума\n",
        "data['query'] = data['query'].apply(lambda x: tokenize_string(x))\n",
        "data['d+'] = data['d+'].apply(lambda x: tokenize_string(x))\n",
        "\n",
        "# создаем K=4 не дубликатов для данного примера\n",
        "data['d1-'] = np.random.permutation(data['d+'].values)\n",
        "data['d2-'] = np.random.permutation(data['d+'].values)\n",
        "data['d3-'] = np.random.permutation(data['d+'].values)\n",
        "data['d4-'] = np.random.permutation(data['d+'].values)\n",
        "\n",
        "# первый пример всегда является дубликатом, все остальные --- нет\n",
        "y = np.zeros((data.shape[0], 5), dtype=int)\n",
        "y[:,0] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_LU75fH-NqDB",
        "colab_type": "code",
        "outputId": "1af2a63d-4a3e-4839-da97-01678a8be476",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>query</th>\n",
              "      <th>d+</th>\n",
              "      <th>is_duplicate</th>\n",
              "      <th>d1-</th>\n",
              "      <th>d2-</th>\n",
              "      <th>d3-</th>\n",
              "      <th>d4-</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
              "      <td>I'm a triple Capricorn (Sun, Moon and ascendan...</td>\n",
              "      <td>1</td>\n",
              "      <td>Which are best mobile phones to buy under 15000?</td>\n",
              "      <td>What books are worth reading in early 20s?</td>\n",
              "      <td>What jobs are available with a bachelor’s degr...</td>\n",
              "      <td>What is the way to watch Comedy Nights with Ka...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>How can I be a good geologist?</td>\n",
              "      <td>What should I do to be a great geologist?</td>\n",
              "      <td>1</td>\n",
              "      <td>Why Central Govt banned old 500 and 1000 Rs no...</td>\n",
              "      <td>How can I efficiently learn while sleeping?</td>\n",
              "      <td>How can I teach myself how to sing?</td>\n",
              "      <td>Who will disrupt Bloomberg?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>23</td>\n",
              "      <td>24</td>\n",
              "      <td>How do I read and find my YouTube comments?</td>\n",
              "      <td>How can I see all my Youtube comments?</td>\n",
              "      <td>1</td>\n",
              "      <td>Does eating prunes help with constipation?</td>\n",
              "      <td>How do I potty train my two-month-old Labrador...</td>\n",
              "      <td>How can you play a Blu Ray DVD on a regular DV...</td>\n",
              "      <td>What are the best places to visit in Kerala fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>25</td>\n",
              "      <td>26</td>\n",
              "      <td>What can make Physics easy to learn?</td>\n",
              "      <td>How can you make physics easy to learn?</td>\n",
              "      <td>1</td>\n",
              "      <td>What are some high paying jobs for a fresher w...</td>\n",
              "      <td>How can I use Twitter for business?</td>\n",
              "      <td>Why does Quora mark my questions as needing im...</td>\n",
              "      <td>How do I become a good computer science engineer?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>27</td>\n",
              "      <td>28</td>\n",
              "      <td>What was your first sexual experience like?</td>\n",
              "      <td>What was your first sexual experience?</td>\n",
              "      <td>1</td>\n",
              "      <td>What are some of the products made from crude ...</td>\n",
              "      <td>Is it healthy to eat a whole avocado every day?</td>\n",
              "      <td>How do I become a good computer science engineer?</td>\n",
              "      <td>How do I potty train my two-month-old Labrador...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    id  qid1  qid2                                              query  \\\n",
              "5    5    11    12  Astrology: I am a Capricorn Sun Cap moon and c...   \n",
              "7    7    15    16                     How can I be a good geologist?   \n",
              "11  11    23    24        How do I read and find my YouTube comments?   \n",
              "12  12    25    26               What can make Physics easy to learn?   \n",
              "13  13    27    28        What was your first sexual experience like?   \n",
              "\n",
              "                                                   d+  is_duplicate  \\\n",
              "5   I'm a triple Capricorn (Sun, Moon and ascendan...             1   \n",
              "7           What should I do to be a great geologist?             1   \n",
              "11             How can I see all my Youtube comments?             1   \n",
              "12            How can you make physics easy to learn?             1   \n",
              "13             What was your first sexual experience?             1   \n",
              "\n",
              "                                                  d1-  \\\n",
              "5    Which are best mobile phones to buy under 15000?   \n",
              "7   Why Central Govt banned old 500 and 1000 Rs no...   \n",
              "11         Does eating prunes help with constipation?   \n",
              "12  What are some high paying jobs for a fresher w...   \n",
              "13  What are some of the products made from crude ...   \n",
              "\n",
              "                                                  d2-  \\\n",
              "5          What books are worth reading in early 20s?   \n",
              "7         How can I efficiently learn while sleeping?   \n",
              "11  How do I potty train my two-month-old Labrador...   \n",
              "12                How can I use Twitter for business?   \n",
              "13    Is it healthy to eat a whole avocado every day?   \n",
              "\n",
              "                                                  d3-  \\\n",
              "5   What jobs are available with a bachelor’s degr...   \n",
              "7                 How can I teach myself how to sing?   \n",
              "11  How can you play a Blu Ray DVD on a regular DV...   \n",
              "12  Why does Quora mark my questions as needing im...   \n",
              "13  How do I become a good computer science engineer?   \n",
              "\n",
              "                                                  d4-  \n",
              "5   What is the way to watch Comedy Nights with Ka...  \n",
              "7                         Who will disrupt Bloomberg?  \n",
              "11  What are the best places to visit in Kerala fo...  \n",
              "12  How do I become a good computer science engineer?  \n",
              "13  How do I potty train my two-month-old Labrador...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "pVGiDE3MO0HX",
        "colab_type": "code",
        "outputId": "53b5cce8-ac72-49bd-de22-9360e0e749c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(380, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "xOO4euI_Ic6w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# фитим токенайзер\n",
        "\n",
        "corpus = data['query'].tolist() + data['d+'].tolist()\n",
        "tok = Tokenizer(num_words=vocab_size)\n",
        "tok.fit_on_texts(corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mwcQ6iz4Ic63",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# векторизуем данные\n",
        "\n",
        "q = vectorize(data['query'].values, tok)\n",
        "d0 = vectorize(data['d+'].values, tok)\n",
        "d1 = vectorize(data['d1-'].values, tok)\n",
        "d2 = vectorize(data['d2-'].values, tok)\n",
        "d3 = vectorize(data['d3-'].values, tok)\n",
        "d4 = vectorize(data['d4-'].values, tok)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ts8erTqqIc6-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# делим датасет на обучение и валидацию\n",
        "\n",
        "x = np.hstack((q, d0, d1, d2, d3, d4)).reshape((-1, 6, time_steps))\n",
        "xtr, xev, ytr, yev = train_test_split(x, y, test_size=0.1, random_state=24)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dI9OQ-r6Sggc",
        "colab_type": "code",
        "outputId": "05f5a5ec-8964-4f62-b133-062e75f587fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(x.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(380, 6, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "l8CJGB31Sslh",
        "colab_type": "code",
        "outputId": "b7290c76-c542-4ccf-96fd-31c93a6df623",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "x[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 230,  445,  231,   13,  445,  925,    2,   21,   36,  446,   49,\n",
              "          44],\n",
              "       [ 230,  231,   13, 1204,   10,  326,    2,   21,  158,  446,   49,\n",
              "          44],\n",
              "       [  30,   12,   15, 1297, 1298,    6,  378,  124, 1299,    0,    0,\n",
              "           0],\n",
              "       [   2,  137,   12, 1339, 1340,   10,  292,  676,    0,    0,    0,\n",
              "           0],\n",
              "       [   2,  123,   12,  765,   32,    8, 1288, 1289,   10,  608,  269,\n",
              "           0],\n",
              "       [   1,   63,    6,  201,  287,  652,   32,  653,   93,   19,    1,\n",
              "        1324]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "GQSUdybpIc7N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## input_fn\n",
        "\n",
        "С помощью tf.data создаем итератор, который будет подавать данные в модель"
      ]
    },
    {
      "metadata": {
        "id": "GiLvQXBDIc7Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def expand_x(x):\n",
        "    return {'q': x[:,0],\n",
        "            'd0': x[:,1],\n",
        "            'd1': x[:,2],\n",
        "            'd2': x[:,3],\n",
        "            'd3': x[:,4],\n",
        "            'd4': x[:,5]}\n",
        "\n",
        "# функция, которая подает данные в модель\n",
        "def input_fn(x, labels, params, is_training):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((x, labels))\n",
        "\n",
        "    if is_training:\n",
        "        dataset = dataset.shuffle(buffer_size=params['train_size'])\n",
        "        dataset = dataset.repeat(count=params['num_epochs'])\n",
        "\n",
        "    dataset = dataset.batch(params['batch_size'])\n",
        "    dataset = dataset.map(lambda x, y: (expand_x(x), y))\n",
        "    dataset = dataset.prefetch(buffer_size=100)\n",
        "    return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hhikSoGLIc7Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model"
      ]
    },
    {
      "metadata": {
        "id": "WeXdBdRFIc7a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Задание 2**\n",
        "\n",
        "Реализуйте функцию, котора считает косинусную близость между тензорами размера **(batch_size, dim)**"
      ]
    },
    {
      "metadata": {
        "id": "q7d0EiF1Ic7b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# hint: try to use tf.nn.l2_normalize, tf.multiply\n",
        "\n",
        "def cosine_sim(a, b):\n",
        "    \"\"\"\n",
        "    Подсчет косинусной близости между двумя тензорами размера (batch_size, dim)\n",
        "    \"\"\"\n",
        "    normalize_a = tf.nn.l2_normalize(a,0)        \n",
        "    normalize_b = tf.nn.l2_normalize(b,0)\n",
        "    \n",
        "    # tf.multiply(normalize_a,normalize_b) должен иметь shape=(batch_size, dim)=(256, 12)\n",
        "    \n",
        "    cos_sim = tf.reduce_sum(tf.multiply(normalize_a,normalize_b), axis=1)\n",
        "    # a cos_sim с shape = (256)\n",
        "\n",
        "    return cos_sim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NXGDba_WIc7i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Задание 3**\n",
        "\n",
        "Реализуйте энкодер, который переводит тензор размера **(batch_size, time_steps, emb_size)** в тензор **(batch_size, new_dim)**\n",
        "\n",
        "<img src=\"https://ai2-s2-public.s3.amazonaws.com/figures/2017-08-08/73d826d4c2363701b88e3e234fe3b8756c0f9671/3-Figure1-1.png\" width=600>\n",
        "\n",
        "\n",
        "Применить два типа свертки: **[kernel_size=3, strides=2, filters=32], [kernel_size=5, strides=3, filters=32]**\n",
        "\n",
        "Над выходами **average-pooling, max-pooling** соответственно. Полученные тензоры сконкатенировать."
      ]
    },
    {
      "metadata": {
        "id": "NiLC0KhjIc7k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_model(features, params, is_training):\n",
        "\n",
        "\n",
        "  emb_matrix = tf.get_variable('embedding_matrix',\n",
        "                             shape=[params['vocab_size'], params['emb_size']],\n",
        "                             dtype=tf.float32)\n",
        "\n",
        "  def encode(sentences):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        sentences: (batch_size, time_steps) последовательности индексов\n",
        "    Returns:\n",
        "        out: (batch_size, new_dim) представление текста в новом пространстве\n",
        "    \"\"\"\n",
        "\n",
        "    # hints: use tf.nn.embedding_lookup, tf.layers.conv1d, tf.reduce_max\n",
        "    # tf.reduce_mean, tf.concat\n",
        "    embs = tf.nn.embedding_lookup(emb_matrix, sentences)\n",
        "\n",
        "    conv_1 = tf.layers.conv1d(embs,\n",
        "                      filters=32,\n",
        "                      kernel_size=3,\n",
        "                      strides=2)\n",
        "    conv_2 = tf.layers.conv1d(embs,\n",
        "                      filters=32,\n",
        "                      kernel_size=5,\n",
        "                      strides=3)\n",
        "    pool_1 = tf.reduce_mean(conv_1, axis=1)\n",
        "    pool_2 = tf.reduce_max(conv_2, axis=1)\n",
        "    cc = tf.concat([pool_1, pool_2], axis=1)\n",
        "    out = tf.layers.dense(cc, 29, activation=tf.nn.relu)\n",
        "    return out\n",
        "\n",
        "\n",
        "  # энкодим все документы\n",
        "  encoded_features = {}        \n",
        "\n",
        "  with tf.variable_scope('enc'):\n",
        "      encoded_features['q'] = encode(features['q'])\n",
        "\n",
        "  for key, value in features.items():\n",
        "      if key != 'q':\n",
        "          with tf.variable_scope('enc', reuse=True):\n",
        "              encoded_features[key] = encode(value)\n",
        "\n",
        "  # считаем косинусные близости между q и всеми документами\n",
        "  cos_sims = {}\n",
        "\n",
        "  for key, value in encoded_features.items():\n",
        "      if key != 'q':\n",
        "          cos_sims[key] = cosine_sim(encoded_features['q'], encoded_features[key])\n",
        "\n",
        "  # конкатинируем косинусные близости\n",
        "\n",
        "  to_concatenate = [cos_sims['d0'], cos_sims['d1'], cos_sims['d2'], cos_sims['d3'], cos_sims['d4']]\n",
        "  concatenated = tf.stack(to_concatenate, axis=1)\n",
        "  \n",
        "  return concatenated, encoded_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Om7M52ByIc7w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Функция потерь:\n",
        "\n",
        "$$J(\\theta) = - \\sum_i y_i \\ln(\\hat{y_i})$$\n",
        "\n",
        "Мы хотим, чтобы $cosine\\_similarity(q, d_0) = 1$, а $cosine\\_similarity(q, d_j) = 0$, где $j \\in \\{1,2,3,4\\}$, тогда лосс будет стремиться к нулю.\n",
        "\n",
        "\n",
        "**Задание 4**\n",
        "\n",
        "Реализовать метрики:\n",
        "\n",
        "* Accuracy\n",
        "* MSE"
      ]
    },
    {
      "metadata": {
        "id": "ldcxmhDGIc7x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model_fn(features, labels, mode, params):\n",
        "    \n",
        "    is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "    \n",
        "    with tf.variable_scope('model'):\n",
        "        logits, _ = build_model(features, params, is_training)\n",
        "        \n",
        "    preds = tf.argmax(logits, axis=1)\n",
        "    \n",
        "    \n",
        "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "        predictions = {'preds': preds, 'logits': logits}\n",
        "        return tf.estimator.EstimatorSpec(mode=mode,\n",
        "                                          predictions=predictions)\n",
        "    \n",
        "    # hints: tf.equal, tf.square, tf.substract, tf.cast, tf.reduce_mean\n",
        "    labels = tf.cast(labels, tf.float32)\n",
        "    accuracy = tf.reduce_mean(tf.cast(tf.abs(labels - logits)<0.5, tf.float32))\n",
        "    mse = tf.reduce_mean(tf.cast(tf.square(labels - logits), tf.float32))\n",
        "    \n",
        "    loss = tf.losses.softmax_cross_entropy(onehot_labels=labels, logits=logits)\n",
        "    \n",
        "    if mode == tf.estimator.ModeKeys.EVAL:\n",
        "        with tf.variable_scope('metrics'):\n",
        "            eval_metrics = {'accuracy': tf.metrics.mean(accuracy),\n",
        "                           'mse': tf.metrics.mean(mse)}\n",
        "        \n",
        "        return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=eval_metrics)\n",
        "    \n",
        "    tf.summary.scalar('accuracy', accuracy)\n",
        "    tf.summary.scalar('mse', mse)\n",
        "    tf.summary.scalar('loss', loss)\n",
        "    \n",
        "    optimizer = tf.train.AdamOptimizer()\n",
        "    \n",
        "    global_step = tf.train.get_global_step()\n",
        "    train_op = optimizer.minimize(loss, global_step=global_step)\n",
        "    \n",
        "    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ePKOy8V1Ic74",
        "colab_type": "code",
        "outputId": "d37fd0ae-c496-47c7-eb71-962e620cd334",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "cell_type": "code",
      "source": [
        "model_params = {\n",
        "    'vocab_size': vocab_size,\n",
        "    'emb_size': 300\n",
        "}\n",
        "\n",
        "config = tf.estimator.RunConfig(tf_random_seed=123,\n",
        "                                model_dir='masha',\n",
        "                                save_summary_steps=5)\n",
        "\n",
        "estimator = tf.estimator.Estimator(model_fn,\n",
        "                                   params=model_params,\n",
        "                                   config=config)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'masha', '_tf_random_seed': 123, '_save_summary_steps': 5, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa51d45da90>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aZiHX93iIc7-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    'batch_size': 256,\n",
        "    'num_epochs': 5,\n",
        "    'train_size': int(len(xtr) * 0.9)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5D6SDVt3Ic8G",
        "colab_type": "code",
        "outputId": "e45532c2-37e2-4e45-fcad-0997a3aa6850",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1343
        }
      },
      "cell_type": "code",
      "source": [
        "estimator.train(lambda: input_fn(xtr, ytr, params=params, is_training=True))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "emb_matrix.shape = (7000, 300)\n",
            "embs.shape = (?, 12, 300)\n",
            "conv_1.shape = (?, 5, 32)\n",
            "conv_2.shape = (?, 3, 32)\n",
            "pool_1.shape = (?, 32)\n",
            "pool_2.shape = (?, 32)\n",
            "cc.shape = (?, 64)\n",
            "out.shape = (?, 29)\n",
            "embs.shape = (?, 12, 300)\n",
            "conv_1.shape = (?, 5, 32)\n",
            "conv_2.shape = (?, 3, 32)\n",
            "pool_1.shape = (?, 32)\n",
            "pool_2.shape = (?, 32)\n",
            "cc.shape = (?, 64)\n",
            "out.shape = (?, 29)\n",
            "embs.shape = (?, 12, 300)\n",
            "conv_1.shape = (?, 5, 32)\n",
            "conv_2.shape = (?, 3, 32)\n",
            "pool_1.shape = (?, 32)\n",
            "pool_2.shape = (?, 32)\n",
            "cc.shape = (?, 64)\n",
            "out.shape = (?, 29)\n",
            "embs.shape = (?, 12, 300)\n",
            "conv_1.shape = (?, 5, 32)\n",
            "conv_2.shape = (?, 3, 32)\n",
            "pool_1.shape = (?, 32)\n",
            "pool_2.shape = (?, 32)\n",
            "cc.shape = (?, 64)\n",
            "out.shape = (?, 29)\n",
            "embs.shape = (?, 12, 300)\n",
            "conv_1.shape = (?, 5, 32)\n",
            "conv_2.shape = (?, 3, 32)\n",
            "pool_1.shape = (?, 32)\n",
            "pool_2.shape = (?, 32)\n",
            "cc.shape = (?, 64)\n",
            "out.shape = (?, 29)\n",
            "embs.shape = (?, 12, 300)\n",
            "conv_1.shape = (?, 5, 32)\n",
            "conv_2.shape = (?, 3, 32)\n",
            "pool_1.shape = (?, 32)\n",
            "pool_2.shape = (?, 32)\n",
            "cc.shape = (?, 64)\n",
            "out.shape = (?, 29)\n",
            "a.shape = (?, 29)\n",
            "cos_sim.shape = (?,)\n",
            "None\n",
            "a.shape = (?, 29)\n",
            "cos_sim.shape = (?,)\n",
            "None\n",
            "a.shape = (?, 29)\n",
            "cos_sim.shape = (?,)\n",
            "None\n",
            "a.shape = (?, 29)\n",
            "cos_sim.shape = (?,)\n",
            "None\n",
            "a.shape = (?, 29)\n",
            "cos_sim.shape = (?,)\n",
            "None\n",
            "cos_simsd0.shape = (?,)\n",
            "to_concatenate.shape = 5\n",
            "concatenated.shape = (?, 5)\n",
            "logits (?, 5)\n",
            "Tensor(\"strided_slice:0\", shape=(?, 5), dtype=float32)\n",
            "preds (?,)\n",
            "label (?, 5)\n",
            "Tensor(\"strided_slice_1:0\", shape=(?, 5), dtype=int64)\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from masha/model.ckpt-7\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 7 into masha/model.ckpt.\n",
            "INFO:tensorflow:loss = 1.5287526, step = 8\n",
            "INFO:tensorflow:Saving checkpoints for 14 into masha/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 1.4857591.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.estimator.estimator.Estimator at 0x7fa51d5d9128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "metadata": {
        "id": "ne-raD9vbnbZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "Vmr8SPxuIc8N",
        "colab_type": "code",
        "outputId": "3fde6568-e646-41e7-e248-37b3ab490994",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1397
        }
      },
      "cell_type": "code",
      "source": [
        "eval_results = estimator.evaluate(lambda: input_fn(xev, yev, params=params, is_training=False))\n",
        "\n",
        "for key, value in eval_results.items():\n",
        "    print(f'{key}: {value}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "emb_matrix.shape = (7000, 300)\n",
            "embs.shape = (?, 12, 300)\n",
            "conv_1.shape = (?, 5, 32)\n",
            "conv_2.shape = (?, 3, 32)\n",
            "pool_1.shape = (?, 32)\n",
            "pool_2.shape = (?, 32)\n",
            "cc.shape = (?, 64)\n",
            "out.shape = (?, 29)\n",
            "embs.shape = (?, 12, 300)\n",
            "conv_1.shape = (?, 5, 32)\n",
            "conv_2.shape = (?, 3, 32)\n",
            "pool_1.shape = (?, 32)\n",
            "pool_2.shape = (?, 32)\n",
            "cc.shape = (?, 64)\n",
            "out.shape = (?, 29)\n",
            "embs.shape = (?, 12, 300)\n",
            "conv_1.shape = (?, 5, 32)\n",
            "conv_2.shape = (?, 3, 32)\n",
            "pool_1.shape = (?, 32)\n",
            "pool_2.shape = (?, 32)\n",
            "cc.shape = (?, 64)\n",
            "out.shape = (?, 29)\n",
            "embs.shape = (?, 12, 300)\n",
            "conv_1.shape = (?, 5, 32)\n",
            "conv_2.shape = (?, 3, 32)\n",
            "pool_1.shape = (?, 32)\n",
            "pool_2.shape = (?, 32)\n",
            "cc.shape = (?, 64)\n",
            "out.shape = (?, 29)\n",
            "embs.shape = (?, 12, 300)\n",
            "conv_1.shape = (?, 5, 32)\n",
            "conv_2.shape = (?, 3, 32)\n",
            "pool_1.shape = (?, 32)\n",
            "pool_2.shape = (?, 32)\n",
            "cc.shape = (?, 64)\n",
            "out.shape = (?, 29)\n",
            "embs.shape = (?, 12, 300)\n",
            "conv_1.shape = (?, 5, 32)\n",
            "conv_2.shape = (?, 3, 32)\n",
            "pool_1.shape = (?, 32)\n",
            "pool_2.shape = (?, 32)\n",
            "cc.shape = (?, 64)\n",
            "out.shape = (?, 29)\n",
            "a.shape = (?, 29)\n",
            "cos_sim.shape = (?,)\n",
            "None\n",
            "a.shape = (?, 29)\n",
            "cos_sim.shape = (?,)\n",
            "None\n",
            "a.shape = (?, 29)\n",
            "cos_sim.shape = (?,)\n",
            "None\n",
            "a.shape = (?, 29)\n",
            "cos_sim.shape = (?,)\n",
            "None\n",
            "a.shape = (?, 29)\n",
            "cos_sim.shape = (?,)\n",
            "None\n",
            "cos_simsd0.shape = (?,)\n",
            "to_concatenate.shape = 5\n",
            "concatenated.shape = (?, 5)\n",
            "logits (?, 5)\n",
            "Tensor(\"strided_slice:0\", shape=(?, 5), dtype=float32)\n",
            "preds (?,)\n",
            "label (?, 5)\n",
            "Tensor(\"strided_slice_1:0\", shape=(?, 5), dtype=int64)\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-10-23-20:32:43\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from masha/model.ckpt-14\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2018-10-23-20:32:43\n",
            "INFO:tensorflow:Saving dict for global step 14: accuracy = 0.8210526, global_step = 14, loss = 1.52593, mse = 0.17366639\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 14: masha/model.ckpt-14\n",
            "accuracy: 0.821052610874176\n",
            "loss: 1.5259300470352173\n",
            "mse: 0.17366638779640198\n",
            "global_step: 14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-KUgJWtgIc8W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "preds = estimator.predict(lambda: input_fn(xev, yev, params=params, is_training=False))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bgbu69puIc8f",
        "colab_type": "code",
        "outputId": "c3e96b6b-55d7-49f2-ca7f-6a8aa8521609",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1156
        }
      },
      "cell_type": "code",
      "source": [
        "logits = []\n",
        "\n",
        "for el in preds:\n",
        "    logits.append(el['logits'])\n",
        "    \n",
        "logits = np.array(logits, dtype=float)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "emb_matrix.shape = (7000, 300)\n",
            "embs.shape = (?, 12, 300)\n",
            "conv_1.shape = (?, 5, 32)\n",
            "conv_2.shape = (?, 3, 32)\n",
            "pool_1.shape = (?, 32)\n",
            "pool_2.shape = (?, 32)\n",
            "cc.shape = (?, 64)\n",
            "out.shape = (?, 29)\n",
            "embs.shape = (?, 12, 300)\n",
            "conv_1.shape = (?, 5, 32)\n",
            "conv_2.shape = (?, 3, 32)\n",
            "pool_1.shape = (?, 32)\n",
            "pool_2.shape = (?, 32)\n",
            "cc.shape = (?, 64)\n",
            "out.shape = (?, 29)\n",
            "embs.shape = (?, 12, 300)\n",
            "conv_1.shape = (?, 5, 32)\n",
            "conv_2.shape = (?, 3, 32)\n",
            "pool_1.shape = (?, 32)\n",
            "pool_2.shape = (?, 32)\n",
            "cc.shape = (?, 64)\n",
            "out.shape = (?, 29)\n",
            "embs.shape = (?, 12, 300)\n",
            "conv_1.shape = (?, 5, 32)\n",
            "conv_2.shape = (?, 3, 32)\n",
            "pool_1.shape = (?, 32)\n",
            "pool_2.shape = (?, 32)\n",
            "cc.shape = (?, 64)\n",
            "out.shape = (?, 29)\n",
            "embs.shape = (?, 12, 300)\n",
            "conv_1.shape = (?, 5, 32)\n",
            "conv_2.shape = (?, 3, 32)\n",
            "pool_1.shape = (?, 32)\n",
            "pool_2.shape = (?, 32)\n",
            "cc.shape = (?, 64)\n",
            "out.shape = (?, 29)\n",
            "embs.shape = (?, 12, 300)\n",
            "conv_1.shape = (?, 5, 32)\n",
            "conv_2.shape = (?, 3, 32)\n",
            "pool_1.shape = (?, 32)\n",
            "pool_2.shape = (?, 32)\n",
            "cc.shape = (?, 64)\n",
            "out.shape = (?, 29)\n",
            "a.shape = (?, 29)\n",
            "cos_sim.shape = (?,)\n",
            "None\n",
            "a.shape = (?, 29)\n",
            "cos_sim.shape = (?,)\n",
            "None\n",
            "a.shape = (?, 29)\n",
            "cos_sim.shape = (?,)\n",
            "None\n",
            "a.shape = (?, 29)\n",
            "cos_sim.shape = (?,)\n",
            "None\n",
            "a.shape = (?, 29)\n",
            "cos_sim.shape = (?,)\n",
            "None\n",
            "cos_simsd0.shape = (?,)\n",
            "to_concatenate.shape = 5\n",
            "concatenated.shape = (?, 5)\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from masha/model.ckpt-7\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}